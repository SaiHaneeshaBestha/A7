{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "\n",
    "# Retrieval-Augmented generation (RAG)\n",
    "\n",
    "RAG is a technique for augmenting LLM knowledge with additional, often private or real-time, data.\n",
    "\n",
    "LLMs can reason about wide-ranging topics, but their knowledge is limited to the public data up to a specific point in time that they were trained on. If you want to build AI applications that can reason about private data or data introduced after a model’s cutoff date, you need to augment the knowledge of the model with the specific information it needs.\n",
    "\n",
    "<img src=\"../figures/RAG-process.png\" >\n",
    "\n",
    "Introducing `ChakyBot`, an innovative chatbot designed to assist Chaky (the instructor) and TA (Gun) in explaining the lesson of the NLP course to students. Leveraging LangChain technology, ChakyBot excels in retrieving information from documents, ensuring a seamless and efficient learning experience for students engaging with the NLP curriculum.\n",
    "\n",
    "1. Prompt\n",
    "2. Retrieval\n",
    "3. Memory\n",
    "4. Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#langchain library\n",
    "#!pip install langchain==0.0.350\n",
    "#LLM\n",
    "#!pip install accelerate==0.25.0\n",
    "#!pip install transformers==4.36.2\n",
    "#!pip install bitsandbytes==0.41.2\n",
    "#Text Embedding\n",
    "#!pip install sentence-transformers==2.2.2\n",
    "#!pip install InstructorEmbedding==1.0.1\n",
    "#vectorstore\n",
    "#!pip install pymupdf==1.23.8\n",
    "#!pip install faiss-gpu==1.7.2\n",
    "#!pip install faiss-cpu==1.7.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prompt\n",
    "\n",
    "A set of instructions or input provided by a user to guide the model's response, helping it understand the context and generate relevant and coherent language-based output, such as answering questions, completing sentences, or engaging in a conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question'], template='HI ,I am AIT LILbot. I am your study program bot .If you are looking for courses offered in AIT and which school offers which courses you can ask me, I am always ready to help you ^-^!\\n    {context}\\n    Question: {question}\\n    Answer:')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "    HI ,I am AIT LILbot. I am your study program bot .If you are looking for courses offered in AIT and which school offers which courses you can ask me, I am always ready to help you ^-^!\n",
    "    {context}\n",
    "    Question: {question}\n",
    "    Answer:\n",
    "    \"\"\".strip()\n",
    "\n",
    "PROMPT = PromptTemplate.from_template(\n",
    "    template = prompt_template\n",
    ")\n",
    "\n",
    "PROMPT\n",
    "#using str.format \n",
    "#The placeholder is defined using curly brackets: {} {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HI ,I am AIT LILbot. I am your study program bot .If you are looking for courses offered in AIT and which school offers which courses you can ask me, I am always ready to help you ^-^!\\n    All programs information are given below.\\n    Question: What are the programs offered?\\n    Answer:'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROMPT.format(\n",
    "    context = \"All programs information are given below.\",\n",
    "    question = \"What are the programs offered?\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : [How to improve prompting (Zero-shot, Few-shot, Chain-of-Thought, etc.](https://github.com/chaklam-silpasuwanchai/Natural-Language-Processing/blob/main/Code/05%20-%20RAG/advance/cot-tot-prompting.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Retrieval\n",
    "\n",
    "1. `Document loaders` : Load documents from many different sources (HTML, PDF, code). \n",
    "2. `Document transformers` : One of the essential steps in document retrieval is breaking down a large document into smaller, relevant chunks to enhance the retrieval process.\n",
    "3. `Text embedding models` : Embeddings capture the semantic meaning of the text, allowing you to quickly and efficiently find other pieces of text that are similar.\n",
    "4. `Vector stores`: there has emerged a need for databases to support efficient storage and searching of these embeddings.\n",
    "5. `Retrievers` : Once the data is in the database, you still need to retrieve it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Document Loaders \n",
    "Use document loaders to load data from a source as Document's. A Document is a piece of text and associated metadata. For example, there are document loaders for loading a simple .txt file, for loading the text contents of any web page, or even for loading a transcript of a YouTube video.\n",
    "\n",
    "[PDF Loader](https://python.langchain.com/docs/modules/data_connection/document_loaders/pdf)\n",
    "\n",
    "[Download Document](https://web.stanford.edu/~jurafsky/slp3/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import pwd\n",
    "except ImportError:\n",
    "    # Handle the ImportError (e.g., provide an alternative implementation or raise a more informative error)\n",
    "    print(\"The pwd module is not available on this platform.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "\n",
    "nlp_docs = 'C:\\\\Users\\\\Haneesha\\\\OneDrive\\\\文件\\\\Boooooookkkkkkssss\\\\Academic Programs - Asian Institute of Technology.pdf'\n",
    "\n",
    "loader = PyMuPDFLoader(nlp_docs)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='3/21/24, 7:37 PM\\nAcademic Programs - Asian Institute of Technology\\nhttps://ait.ac.th/academics/programs/\\n1/9\\nHome (h�ps://ait.ac.th) > Academics (h�ps://ait.ac.th… > Academic Programs\\nAcademic Programs\\nWe oﬀer various degree programs. You\\'ll sample courses in a wide range of\\nsubjects before immersing yourself in one of these focused areas.\\nIn this sec�on\\nShow ﬁlters\\n (/)\\nWe use cookies on our website to give you the most relevant experience by remembering your preferences and repeat visits. By clicking “Accept\\nAll”, you consent to the use of ALL the cookies. However, you may visit \"Cookie Settings\" to provide a controlled consent.\\nCookie Settings\\nAccept All\\n', metadata={'source': 'C:\\\\Users\\\\Haneesha\\\\OneDrive\\\\文件\\\\Boooooookkkkkkssss\\\\Academic Programs - Asian Institute of Technology.pdf', 'file_path': 'C:\\\\Users\\\\Haneesha\\\\OneDrive\\\\文件\\\\Boooooookkkkkkssss\\\\Academic Programs - Asian Institute of Technology.pdf', 'page': 0, 'total_pages': 9, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36', 'producer': 'Skia/PDF m122', 'creationDate': \"D:20240321123743+00'00'\", 'modDate': \"D:20240321123743+00'00'\", 'trapped': ''}),\n",
       " Document(page_content='3/21/24, 7:37 PM\\nAcademic Programs - Asian Institute of Technology\\nhttps://ait.ac.th/academics/programs/\\n2/9\\nAll Programs\\nAgri-Business Management\\n(ABM)\\nAgricultural Systems And\\nEngineering (ASE)\\nAquaculture and Aqua�c\\nResources Management\\n(AARM)\\nBio-Nano Materials Science\\nand Engineering (BNMSE)\\nClimate Change and\\nSustainable Development\\n(CCSD)\\nComputer Science (CS)\\n (/)\\nWe use cookies on our website to give you the most relevant experience by remembering your preferences and repeat visits. By clicking “Accept\\nAll”, you consent to the use of ALL the cookies. However, you may visit \"Cookie Settings\" to provide a controlled consent.\\nCookie Settings\\nAccept All\\n', metadata={'source': 'C:\\\\Users\\\\Haneesha\\\\OneDrive\\\\文件\\\\Boooooookkkkkkssss\\\\Academic Programs - Asian Institute of Technology.pdf', 'file_path': 'C:\\\\Users\\\\Haneesha\\\\OneDrive\\\\文件\\\\Boooooookkkkkkssss\\\\Academic Programs - Asian Institute of Technology.pdf', 'page': 1, 'total_pages': 9, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36', 'producer': 'Skia/PDF m122', 'creationDate': \"D:20240321123743+00'00'\", 'modDate': \"D:20240321123743+00'00'\", 'trapped': ''}),\n",
       " Document(page_content='3/21/24, 7:37 PM\\nAcademic Programs - Asian Institute of Technology\\nhttps://ait.ac.th/academics/programs/\\n3/9\\nConstruc�on, Engineering\\nand Infrastructure\\nManagement (CEIM)\\nData Science and AI (DSAI)\\nDevelopment and\\nSustainability (DS)\\nDevelopment Planning\\nManagement and\\nInnova�on (DPMI)\\nDisaster Preparedness\\nMi�ga�on and Management\\n(DPMM)\\nDoctor of Philosophy (Ph.D.)\\nin Management\\n (/)\\nWe use cookies on our website to give you the most relevant experience by remembering your preferences and repeat visits. By clicking “Accept\\nAll”, you consent to the use of ALL the cookies. However, you may visit \"Cookie Settings\" to provide a controlled consent.\\nCookie Settings\\nAccept All\\n', metadata={'source': 'C:\\\\Users\\\\Haneesha\\\\OneDrive\\\\文件\\\\Boooooookkkkkkssss\\\\Academic Programs - Asian Institute of Technology.pdf', 'file_path': 'C:\\\\Users\\\\Haneesha\\\\OneDrive\\\\文件\\\\Boooooookkkkkkssss\\\\Academic Programs - Asian Institute of Technology.pdf', 'page': 2, 'total_pages': 9, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36', 'producer': 'Skia/PDF m122', 'creationDate': \"D:20240321123743+00'00'\", 'modDate': \"D:20240321123743+00'00'\", 'trapped': ''}),\n",
       " Document(page_content='3/21/24, 7:37 PM\\nAcademic Programs - Asian Institute of Technology\\nhttps://ait.ac.th/academics/programs/\\n4/9\\nDoctorate of Business\\nAdministra�on (DBA)\\nDual Degree Master’s\\nProgram with Telecom Sud\\nParis (France)\\nDual Degree Master’s\\nProgram in Data Science\\nand AI with Brunel\\nUniversity London (UK)\\nDual Degree Master’s\\nProgram in Geotechnical\\nand Earth Resources\\nEngineering with Colorado\\nState University (USA)\\nDual Degree Master’s\\nProgram in Water\\nEngineering and\\nManagement with Colorado\\nState University (USA)\\nDual Degree Master’s\\nProgram in Water\\nEngineering and\\nManagement with the\\nUniversity of Iowa (USA)\\n (/)\\nWe use cookies on our website to give you the most relevant experience by remembering your preferences and repeat visits. By clicking “Accept\\nAll”, you consent to the use of ALL the cookies. However, you may visit \"Cookie Settings\" to provide a controlled consent.\\nCookie Settings\\nAccept All\\n', metadata={'source': 'C:\\\\Users\\\\Haneesha\\\\OneDrive\\\\文件\\\\Boooooookkkkkkssss\\\\Academic Programs - Asian Institute of Technology.pdf', 'file_path': 'C:\\\\Users\\\\Haneesha\\\\OneDrive\\\\文件\\\\Boooooookkkkkkssss\\\\Academic Programs - Asian Institute of Technology.pdf', 'page': 3, 'total_pages': 9, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36', 'producer': 'Skia/PDF m122', 'creationDate': \"D:20240321123743+00'00'\", 'modDate': \"D:20240321123743+00'00'\", 'trapped': ''}),\n",
       " Document(page_content='3/21/24, 7:37 PM\\nAcademic Programs - Asian Institute of Technology\\nhttps://ait.ac.th/academics/programs/\\n5/9\\nDual Degree Program with\\nUniversity of Wollongong\\n(Australia)\\nEngineering\\nEntrepreneurship\\nEnvironmental Engineering\\nand Management (EEM)\\nFood Engineering and\\nBioprocess Technology\\n(FEBT)\\nFood Innova�on, Nutri�on\\nand Health (FINH)\\nGender and Development\\nStudies (GDS)\\nN\\nt\\n (/)\\nWe use cookies on our website to give you the most relevant experience by remembering your preferences and repeat visits. By clicking “Accept\\nAll”, you consent to the use of ALL the cookies. However, you may visit \"Cookie Settings\" to provide a controlled consent.\\nCookie Settings\\nAccept All\\n', metadata={'source': 'C:\\\\Users\\\\Haneesha\\\\OneDrive\\\\文件\\\\Boooooookkkkkkssss\\\\Academic Programs - Asian Institute of Technology.pdf', 'file_path': 'C:\\\\Users\\\\Haneesha\\\\OneDrive\\\\文件\\\\Boooooookkkkkkssss\\\\Academic Programs - Asian Institute of Technology.pdf', 'page': 4, 'total_pages': 9, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36', 'producer': 'Skia/PDF m122', 'creationDate': \"D:20240321123743+00'00'\", 'modDate': \"D:20240321123743+00'00'\", 'trapped': ''}),\n",
       " Document(page_content='3/21/24, 7:37 PM\\nAcademic Programs - Asian Institute of Technology\\nhttps://ait.ac.th/academics/programs/\\n6/9\\n1\\n2\\n3 Next\\n»\\n (/)\\nP.O. Box 4, 58 Moo 9, Km. 42, Paholyothin Highway, Klong Luang, Pathum Thani 12120 Thailand\\n(+66) 25245000, (+66) 25160110-44\\nAbout\\nAcademics\\nApply to AIT\\n (/)\\nWe use cookies on our website to give you the most relevant experience by remembering your preferences and repeat visits. By clicking “Accept\\nAll”, you consent to the use of ALL the cookies. However, you may visit \"Cookie Settings\" to provide a controlled consent.\\nCookie Settings\\nAccept All\\n', metadata={'source': 'C:\\\\Users\\\\Haneesha\\\\OneDrive\\\\文件\\\\Boooooookkkkkkssss\\\\Academic Programs - Asian Institute of Technology.pdf', 'file_path': 'C:\\\\Users\\\\Haneesha\\\\OneDrive\\\\文件\\\\Boooooookkkkkkssss\\\\Academic Programs - Asian Institute of Technology.pdf', 'page': 5, 'total_pages': 9, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36', 'producer': 'Skia/PDF m122', 'creationDate': \"D:20240321123743+00'00'\", 'modDate': \"D:20240321123743+00'00'\", 'trapped': ''}),\n",
       " Document(page_content='3/21/24, 7:37 PM\\nAcademic Programs - Asian Institute of Technology\\nhttps://ait.ac.th/academics/programs/\\n7/9\\nAbout AIT (https://ait.ac.th/about/)\\nFacts and ﬁgures\\n(https://ait.ac.th/about/facts-and-\\nﬁgures/)\\nRankings\\n(https://ait.ac.th/about/rankings/)\\nLeadership\\n(https://ait.ac.th/about/leadership/)\\nPeople (https://ait.ac.th/about/meet-\\nour-faculty/)\\nMeet our faculty\\n(https://ait.ac.th/about/meet-our-\\nfaculty/)\\nMeet our staff\\n(https://ait.ac.th/about/meet-our-staff/)\\nLocation\\n(https://ait.ac.th/about/location/)\\nCenters\\n(https://ait.ac.th/about/centers/)\\nAcademic calendar\\n(https://ait.ac.th/academics/calendar/)\\nAcademic Programs\\n(https://ait.ac.th/academics/programs/)\\nStudy options\\n(https://ait.ac.th/academics/study-\\noptions/)\\nStudent opportunities\\n(https://ait.ac.th/academics/student-\\nopportunities/)\\nSchools\\n(https://ait.ac.th/academics/schools/)\\nAdmissions\\n(https://ait.ac.th/admissions/)\\nFinancial aid\\n(https://ait.ac.th/ﬁnancial-aid/)\\nTuition and fees\\n(https://ait.ac.th/tuition-and-fees/)\\nStudent housing\\n(https://ait.ac.th/student-housing/)\\nApply online (https://ait.ac.th/apply-\\nonline/)\\nResearch\\nResearch Centers\\n(https://ait.ac.th/research-centers/)\\nCampus life\\nHousing (https://ait.ac.th/housing/)\\nDining (https://ait.ac.th/dining/)\\nPartners\\n(h�ps://ait.ac.th/partners/)\\n (/)\\nWe use cookies on our website to give you the most relevant experience by remembering your preferences and repeat visits. By clicking “Accept\\nAll”, you consent to the use of ALL the cookies. However, you may visit \"Cookie Settings\" to provide a controlled consent.\\nCookie Settings\\nAccept All\\n', metadata={'source': 'C:\\\\Users\\\\Haneesha\\\\OneDrive\\\\文件\\\\Boooooookkkkkkssss\\\\Academic Programs - Asian Institute of Technology.pdf', 'file_path': 'C:\\\\Users\\\\Haneesha\\\\OneDrive\\\\文件\\\\Boooooookkkkkkssss\\\\Academic Programs - Asian Institute of Technology.pdf', 'page': 6, 'total_pages': 9, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36', 'producer': 'Skia/PDF m122', 'creationDate': \"D:20240321123743+00'00'\", 'modDate': \"D:20240321123743+00'00'\", 'trapped': ''}),\n",
       " Document(page_content='3/21/24, 7:37 PM\\nAcademic Programs - Asian Institute of Technology\\nhttps://ait.ac.th/academics/programs/\\n8/9\\nResearch Themes\\n(https://ait.ac.th/research-themes/)\\nResearch Projects\\n(https://ait.ac.th/research-projects/)\\nResearch Publications\\n(https://ait.ac.th/research-and-\\npublication/)\\nHealth & Wellness\\n(https://ait.ac.th/health-wellness/)\\nCultural diversity\\n(https://ait.ac.th/cultural-diversity/)\\nAthletics (https://ait.ac.th/athletcis/)\\nCareer development\\n(https://ait.ac.th/career-\\ndevelopment/)\\nFacilities (https://ait.ac.th/facilities/)\\nVirtual tour (https://ait.ac.th/virtual-\\ntour/)\\nNews\\n(h�ps://ait.ac.th/news/)\\nEvents\\n(h�ps://ait.ac.th/events/)\\nKey thema�c areas\\n(h�ps://ait.ac.th/climate-\\nchange/)\\nWork at AIT\\n(h�ps://ait.ac.th/opportuni�es/)\\nBranding\\n(h�ps://ait.ac.th/branding/)\\nContact\\n(h�ps://ait.ac.th/contact/)\\nA-Z Units\\n(h�ps://ait.ac.th/a-z-units/)\\nTerms and conditions (https://ait.ac.th/terms-conditions/)\\nPrivacy Policy (https://ait.ac.th/privacy-policy/)\\n (/)\\nWe use cookies on our website to give you the most relevant experience by remembering your preferences and repeat visits. By clicking “Accept\\nAll”, you consent to the use of ALL the cookies. However, you may visit \"Cookie Settings\" to provide a controlled consent.\\nCookie Settings\\nAccept All\\n', metadata={'source': 'C:\\\\Users\\\\Haneesha\\\\OneDrive\\\\文件\\\\Boooooookkkkkkssss\\\\Academic Programs - Asian Institute of Technology.pdf', 'file_path': 'C:\\\\Users\\\\Haneesha\\\\OneDrive\\\\文件\\\\Boooooookkkkkkssss\\\\Academic Programs - Asian Institute of Technology.pdf', 'page': 7, 'total_pages': 9, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36', 'producer': 'Skia/PDF m122', 'creationDate': \"D:20240321123743+00'00'\", 'modDate': \"D:20240321123743+00'00'\", 'trapped': ''}),\n",
       " Document(page_content='3/21/24, 7:37 PM\\nAcademic Programs - Asian Institute of Technology\\nhttps://ait.ac.th/academics/programs/\\n9/9\\n©2022 Asian Institute of Technology. All Rights Reserved. - Designed by Outsourcify (https://outsourcify.net)\\n (/)\\nWe use cookies on our website to give you the most relevant experience by remembering your preferences and repeat visits. By clicking “Accept\\nAll”, you consent to the use of ALL the cookies. However, you may visit \"Cookie Settings\" to provide a controlled consent.\\nCookie Settings\\nAccept All\\n', metadata={'source': 'C:\\\\Users\\\\Haneesha\\\\OneDrive\\\\文件\\\\Boooooookkkkkkssss\\\\Academic Programs - Asian Institute of Technology.pdf', 'file_path': 'C:\\\\Users\\\\Haneesha\\\\OneDrive\\\\文件\\\\Boooooookkkkkkssss\\\\Academic Programs - Asian Institute of Technology.pdf', 'page': 8, 'total_pages': 9, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36', 'producer': 'Skia/PDF m122', 'creationDate': \"D:20240321123743+00'00'\", 'modDate': \"D:20240321123743+00'00'\", 'trapped': ''})]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='3/21/24, 7:37 PM\\nAcademic Programs - Asian Institute of Technology\\nhttps://ait.ac.th/academics/programs/\\n2/9\\nAll Programs\\nAgri-Business Management\\n(ABM)\\nAgricultural Systems And\\nEngineering (ASE)\\nAquaculture and Aqua�c\\nResources Management\\n(AARM)\\nBio-Nano Materials Science\\nand Engineering (BNMSE)\\nClimate Change and\\nSustainable Development\\n(CCSD)\\nComputer Science (CS)\\n (/)\\nWe use cookies on our website to give you the most relevant experience by remembering your preferences and repeat visits. By clicking “Accept\\nAll”, you consent to the use of ALL the cookies. However, you may visit \"Cookie Settings\" to provide a controlled consent.\\nCookie Settings\\nAccept All\\n', metadata={'source': 'C:\\\\Users\\\\Haneesha\\\\OneDrive\\\\文件\\\\Boooooookkkkkkssss\\\\Academic Programs - Asian Institute of Technology.pdf', 'file_path': 'C:\\\\Users\\\\Haneesha\\\\OneDrive\\\\文件\\\\Boooooookkkkkkssss\\\\Academic Programs - Asian Institute of Technology.pdf', 'page': 1, 'total_pages': 9, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36', 'producer': 'Skia/PDF m122', 'creationDate': \"D:20240321123743+00'00'\", 'modDate': \"D:20240321123743+00'00'\", 'trapped': ''})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Document Transformers\n",
    "\n",
    "This text splitter is the recommended one for generic text. It is parameterized by a list of characters. It tries to split on them in order until the chunks are small enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 700,\n",
    "    chunk_overlap = 100\n",
    ")\n",
    "\n",
    "doc = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='3/21/24, 7:37 PM\\nAcademic Programs - Asian Institute of Technology\\nhttps://ait.ac.th/academics/programs/\\n2/9\\nAll Programs\\nAgri-Business Management\\n(ABM)\\nAgricultural Systems And\\nEngineering (ASE)\\nAquaculture and Aqua�c\\nResources Management\\n(AARM)\\nBio-Nano Materials Science\\nand Engineering (BNMSE)\\nClimate Change and\\nSustainable Development\\n(CCSD)\\nComputer Science (CS)\\n (/)\\nWe use cookies on our website to give you the most relevant experience by remembering your preferences and repeat visits. By clicking “Accept\\nAll”, you consent to the use of ALL the cookies. However, you may visit \"Cookie Settings\" to provide a controlled consent.\\nCookie Settings\\nAccept All', metadata={'source': 'C:\\\\Users\\\\Haneesha\\\\OneDrive\\\\文件\\\\Boooooookkkkkkssss\\\\Academic Programs - Asian Institute of Technology.pdf', 'file_path': 'C:\\\\Users\\\\Haneesha\\\\OneDrive\\\\文件\\\\Boooooookkkkkkssss\\\\Academic Programs - Asian Institute of Technology.pdf', 'page': 1, 'total_pages': 9, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36', 'producer': 'Skia/PDF m122', 'creationDate': \"D:20240321123743+00'00'\", 'modDate': \"D:20240321123743+00'00'\", 'trapped': ''})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Text Embedding Models\n",
    "Embeddings create a vector representation of a piece of text. This is useful because it means we can think about text in the vector space, and do things like semantic search where we look for pieces of text that are most similar in the vector space.\n",
    "\n",
    "*Note* Instructor Model : [Huggingface](gingface.co/hkunlp/instructor-base) | [Paper](https://arxiv.org/abs/2212.09741)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Haneesha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\InstructorEmbedding\\instructor.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import trange\n",
      "c:\\Users\\Haneesha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01f3ee8498c34c85877f17f13fe0bf79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbb992cdc7244b8995915018c4e6b83f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/270 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3002673d06ce41998d8c4c0d84ad85f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2_Dense/config.json:   0%|          | 0.00/115 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "236a79d5505147b383afad011ec4caa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "456289986a2c4f28bbd0dd64108f3b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/66.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0703dcbf6e849f6bdc045cef7fa66af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a19512c50a24414081028aba1e1029ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07ba6cb268d74059ad8d740981e2e6f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/439M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec0010721ee7446694f25ea4bc3e29e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6c01797ad6f4610a17337b3e11ab4e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "964ede9137f04496b5ca6584b5665893",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "153b719a50de4ed7999997261eb1b1f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d27716b4d1d41f299a94bc2b15585d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.43k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6dd0da64a65454596824199da51084d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/461 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Haneesha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Users\\Haneesha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "\n",
    "model_name = 'hkunlp/instructor-base'\n",
    "\n",
    "embedding_model = HuggingFaceInstructEmbeddings(\n",
    "    model_name = model_name,\n",
    "    model_kwargs = {\"device\" : device}\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Vector Stores\n",
    "\n",
    "One of the most common ways to store and search over unstructured data is to embed it and store the resulting embedding vectors, and then at query time to embed the unstructured query and retrieve the embedding vectors that are 'most similar' to the embedded query. A vector store takes care of storing embedded data and performing vector search for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create path done\n"
     ]
    }
   ],
   "source": [
    "#locate vectorstore\n",
    "vector_path = '../vector-store'\n",
    "if not os.path.exists(vector_path):\n",
    "    os.makedirs(vector_path)\n",
    "    print('create path done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save vector locally\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "vectordb = FAISS.from_documents(\n",
    "    documents = doc,\n",
    "    embedding = embedding_model\n",
    ")\n",
    "\n",
    "db_file_name = 'nlp_stanford'\n",
    "\n",
    "vectordb.save_local(\n",
    "    folder_path = os.path.join(vector_path, db_file_name),\n",
    "    index_name = 'nlp' #default index\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 retrievers\n",
    "A retriever is an interface that returns documents given an unstructured query. It is more general than a vector store. A retriever does not need to be able to store documents, only to return (or retrieve) them. Vector stores can be used as the backbone of a retriever, but there are other types of retrievers as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = FAISS.load_local(\n",
    "    folder_path = os.path.join(vector_path, db_file_name),\n",
    "    embeddings = embedding_model,\n",
    "    index_name = 'nlp', #default index\n",
    "    allow_dangerous_deserialization = True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The de-serialization relies loading a pickle file. Pickle files can be modified to deliver a malicious payload that results in execution of arbitrary code on your machine.You will need to set `allow_dangerous_deserialization` to `True` to enable deserialization. If you do this, make sure that you trust the source of the data. For example, if you are loading a file that you created, and no that no one else has modified the file, then this is safe to do. Do not set this to `True` if you are loading a file from an untrusted source (e.g., some random site on the internet.).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m db_file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnlp_stanford\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FAISS\n\u001b[1;32m----> 7\u001b[0m vectordb \u001b[38;5;241m=\u001b[39m \u001b[43mFAISS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_local\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvector_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb_file_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43membedding_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnlp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#default index\u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m \u001b[43m)\u001b[49m   \n",
      "File \u001b[1;32mc:\\Users\\Haneesha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:1078\u001b[0m, in \u001b[0;36mFAISS.load_local\u001b[1;34m(cls, folder_path, embeddings, index_name, allow_dangerous_deserialization, **kwargs)\u001b[0m\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load FAISS index, docstore, and index_to_docstore_id from disk.\u001b[39;00m\n\u001b[0;32m   1064\u001b[0m \n\u001b[0;32m   1065\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1075\u001b[0m \u001b[38;5;124;03m    asynchronous: whether to use async version or not\u001b[39;00m\n\u001b[0;32m   1076\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1077\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_dangerous_deserialization:\n\u001b[1;32m-> 1078\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1079\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe de-serialization relies loading a pickle file. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1080\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPickle files can be modified to deliver a malicious payload that \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1081\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults in execution of arbitrary code on your machine.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1082\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou will need to set `allow_dangerous_deserialization` to `True` to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1083\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menable deserialization. If you do this, make sure that you \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1084\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrust the source of the data. For example, if you are loading a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1085\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile that you created, and no that no one else has modified the file, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1086\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthen this is safe to do. Do not set this to `True` if you are loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1087\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma file from an untrusted source (e.g., some random site on the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1088\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minternet.).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1089\u001b[0m     )\n\u001b[0;32m   1090\u001b[0m path \u001b[38;5;241m=\u001b[39m Path(folder_path)\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;66;03m# load index separately since it is not picklable\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: The de-serialization relies loading a pickle file. Pickle files can be modified to deliver a malicious payload that results in execution of arbitrary code on your machine.You will need to set `allow_dangerous_deserialization` to `True` to enable deserialization. If you do this, make sure that you trust the source of the data. For example, if you are loading a file that you created, and no that no one else has modified the file, then this is safe to do. Do not set this to `True` if you are loading a file from an untrusted source (e.g., some random site on the internet.)."
     ]
    }
   ],
   "source": [
    "#calling vector from local\n",
    "vector_path = '../vector-store'\n",
    "db_file_name = 'nlp_stanford'\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "vectordb = FAISS.load_local(\n",
    "    folder_path = os.path.join(vector_path, db_file_name),\n",
    "    embeddings = embedding_model,\n",
    "    index_name = 'nlp' #default index\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ready to use\n",
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='3/21/24, 7:37 PM\\nAcademic Programs - Asian Institute of Technology\\nhttps://ait.ac.th/academics/programs/\\n2/9\\nAll Programs\\nAgri-Business Management\\n(ABM)\\nAgricultural Systems And\\nEngineering (ASE)\\nAquaculture and Aqua�c\\nResources Management\\n(AARM)\\nBio-Nano Materials Science\\nand Engineering (BNMSE)\\nClimate Change and\\nSustainable Development\\n(CCSD)\\nComputer Science (CS)\\n (/)\\nWe use cookies on our website to give you the most relevant experience by remembering your preferences and repeat visits. By clicking “Accept\\nAll”, you consent to the use of ALL the cookies. However, you may visit \"Cookie Settings\" to provide a controlled consent.\\nCookie Settings\\nAccept All', metadata={'source': 'C:\\\\Users\\\\Haneesha\\\\OneDrive\\\\文件\\\\Boooooookkkkkkssss\\\\Academic Programs - Asian Institute of Technology.pdf', 'file_path': 'C:\\\\Users\\\\Haneesha\\\\OneDrive\\\\文件\\\\Boooooookkkkkkssss\\\\Academic Programs - Asian Institute of Technology.pdf', 'page': 1, 'total_pages': 9, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36', 'producer': 'Skia/PDF m122', 'creationDate': \"D:20240321123743+00'00'\", 'modDate': \"D:20240321123743+00'00'\", 'trapped': ''}),\n",
       " Document(page_content='3/21/24, 7:37 PM\\nAcademic Programs - Asian Institute of Technology\\nhttps://ait.ac.th/academics/programs/\\n4/9\\nDoctorate of Business\\nAdministra�on (DBA)\\nDual Degree Master’s\\nProgram with Telecom Sud\\nParis (France)\\nDual Degree Master’s\\nProgram in Data Science\\nand AI with Brunel\\nUniversity London (UK)\\nDual Degree Master’s\\nProgram in Geotechnical\\nand Earth Resources\\nEngineering with Colorado\\nState University (USA)\\nDual Degree Master’s\\nProgram in Water\\nEngineering and\\nManagement with Colorado\\nState University (USA)\\nDual Degree Master’s\\nProgram in Water\\nEngineering and\\nManagement with the\\nUniversity of Iowa (USA)\\n (/)', metadata={'source': 'C:\\\\Users\\\\Haneesha\\\\OneDrive\\\\文件\\\\Boooooookkkkkkssss\\\\Academic Programs - Asian Institute of Technology.pdf', 'file_path': 'C:\\\\Users\\\\Haneesha\\\\OneDrive\\\\文件\\\\Boooooookkkkkkssss\\\\Academic Programs - Asian Institute of Technology.pdf', 'page': 3, 'total_pages': 9, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36', 'producer': 'Skia/PDF m122', 'creationDate': \"D:20240321123743+00'00'\", 'modDate': \"D:20240321123743+00'00'\", 'trapped': ''}),\n",
       " Document(page_content='3/21/24, 7:37 PM\\nAcademic Programs - Asian Institute of Technology\\nhttps://ait.ac.th/academics/programs/\\n3/9\\nConstruc�on, Engineering\\nand Infrastructure\\nManagement (CEIM)\\nData Science and AI (DSAI)\\nDevelopment and\\nSustainability (DS)\\nDevelopment Planning\\nManagement and\\nInnova�on (DPMI)\\nDisaster Preparedness\\nMi�ga�on and Management\\n(DPMM)\\nDoctor of Philosophy (Ph.D.)\\nin Management\\n (/)\\nWe use cookies on our website to give you the most relevant experience by remembering your preferences and repeat visits. By clicking “Accept\\nAll”, you consent to the use of ALL the cookies. However, you may visit \"Cookie Settings\" to provide a controlled consent.\\nCookie Settings\\nAccept All', metadata={'source': 'C:\\\\Users\\\\Haneesha\\\\OneDrive\\\\文件\\\\Boooooookkkkkkssss\\\\Academic Programs - Asian Institute of Technology.pdf', 'file_path': 'C:\\\\Users\\\\Haneesha\\\\OneDrive\\\\文件\\\\Boooooookkkkkkssss\\\\Academic Programs - Asian Institute of Technology.pdf', 'page': 2, 'total_pages': 9, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36', 'producer': 'Skia/PDF m122', 'creationDate': \"D:20240321123743+00'00'\", 'modDate': \"D:20240321123743+00'00'\", 'trapped': ''}),\n",
       " Document(page_content='Program in Water\\nEngineering and\\nManagement with the\\nUniversity of Iowa (USA)\\n (/)\\nWe use cookies on our website to give you the most relevant experience by remembering your preferences and repeat visits. By clicking “Accept\\nAll”, you consent to the use of ALL the cookies. However, you may visit \"Cookie Settings\" to provide a controlled consent.\\nCookie Settings\\nAccept All', metadata={'source': 'C:\\\\Users\\\\Haneesha\\\\OneDrive\\\\文件\\\\Boooooookkkkkkssss\\\\Academic Programs - Asian Institute of Technology.pdf', 'file_path': 'C:\\\\Users\\\\Haneesha\\\\OneDrive\\\\文件\\\\Boooooookkkkkkssss\\\\Academic Programs - Asian Institute of Technology.pdf', 'page': 3, 'total_pages': 9, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36', 'producer': 'Skia/PDF m122', 'creationDate': \"D:20240321123743+00'00'\", 'modDate': \"D:20240321123743+00'00'\", 'trapped': ''})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.get_relevant_documents(\"What are the course structure in Agri-Business Management?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='3/21/24, 7:37 PM\\nAcademic Programs - Asian Institute of Technology\\nhttps://ait.ac.th/academics/programs/\\n9/9\\n©2022 Asian Institute of Technology. All Rights Reserved. - Designed by Outsourcify (https://outsourcify.net)\\n (/)\\nWe use cookies on our website to give you the most relevant experience by remembering your preferences and repeat visits. By clicking “Accept\\nAll”, you consent to the use of ALL the cookies. However, you may visit \"Cookie Settings\" to provide a controlled consent.\\nCookie Settings\\nAccept All', metadata={'source': 'C:\\\\Users\\\\Haneesha\\\\OneDrive\\\\文件\\\\Boooooookkkkkkssss\\\\Academic Programs - Asian Institute of Technology.pdf', 'file_path': 'C:\\\\Users\\\\Haneesha\\\\OneDrive\\\\文件\\\\Boooooookkkkkkssss\\\\Academic Programs - Asian Institute of Technology.pdf', 'page': 8, 'total_pages': 9, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36', 'producer': 'Skia/PDF m122', 'creationDate': \"D:20240321123743+00'00'\", 'modDate': \"D:20240321123743+00'00'\", 'trapped': ''}),\n",
       " Document(page_content='3/21/24, 7:37 PM\\nAcademic Programs - Asian Institute of Technology\\nhttps://ait.ac.th/academics/programs/\\n3/9\\nConstruc�on, Engineering\\nand Infrastructure\\nManagement (CEIM)\\nData Science and AI (DSAI)\\nDevelopment and\\nSustainability (DS)\\nDevelopment Planning\\nManagement and\\nInnova�on (DPMI)\\nDisaster Preparedness\\nMi�ga�on and Management\\n(DPMM)\\nDoctor of Philosophy (Ph.D.)\\nin Management\\n (/)\\nWe use cookies on our website to give you the most relevant experience by remembering your preferences and repeat visits. By clicking “Accept\\nAll”, you consent to the use of ALL the cookies. However, you may visit \"Cookie Settings\" to provide a controlled consent.\\nCookie Settings\\nAccept All', metadata={'source': 'C:\\\\Users\\\\Haneesha\\\\OneDrive\\\\文件\\\\Boooooookkkkkkssss\\\\Academic Programs - Asian Institute of Technology.pdf', 'file_path': 'C:\\\\Users\\\\Haneesha\\\\OneDrive\\\\文件\\\\Boooooookkkkkkssss\\\\Academic Programs - Asian Institute of Technology.pdf', 'page': 2, 'total_pages': 9, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36', 'producer': 'Skia/PDF m122', 'creationDate': \"D:20240321123743+00'00'\", 'modDate': \"D:20240321123743+00'00'\", 'trapped': ''}),\n",
       " Document(page_content='3/21/24, 7:37 PM\\nAcademic Programs - Asian Institute of Technology\\nhttps://ait.ac.th/academics/programs/\\n2/9\\nAll Programs\\nAgri-Business Management\\n(ABM)\\nAgricultural Systems And\\nEngineering (ASE)\\nAquaculture and Aqua�c\\nResources Management\\n(AARM)\\nBio-Nano Materials Science\\nand Engineering (BNMSE)\\nClimate Change and\\nSustainable Development\\n(CCSD)\\nComputer Science (CS)\\n (/)\\nWe use cookies on our website to give you the most relevant experience by remembering your preferences and repeat visits. By clicking “Accept\\nAll”, you consent to the use of ALL the cookies. However, you may visit \"Cookie Settings\" to provide a controlled consent.\\nCookie Settings\\nAccept All', metadata={'source': 'C:\\\\Users\\\\Haneesha\\\\OneDrive\\\\文件\\\\Boooooookkkkkkssss\\\\Academic Programs - Asian Institute of Technology.pdf', 'file_path': 'C:\\\\Users\\\\Haneesha\\\\OneDrive\\\\文件\\\\Boooooookkkkkkssss\\\\Academic Programs - Asian Institute of Technology.pdf', 'page': 1, 'total_pages': 9, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36', 'producer': 'Skia/PDF m122', 'creationDate': \"D:20240321123743+00'00'\", 'modDate': \"D:20240321123743+00'00'\", 'trapped': ''}),\n",
       " Document(page_content='3/21/24, 7:37 PM\\nAcademic Programs - Asian Institute of Technology\\nhttps://ait.ac.th/academics/programs/\\n4/9\\nDoctorate of Business\\nAdministra�on (DBA)\\nDual Degree Master’s\\nProgram with Telecom Sud\\nParis (France)\\nDual Degree Master’s\\nProgram in Data Science\\nand AI with Brunel\\nUniversity London (UK)\\nDual Degree Master’s\\nProgram in Geotechnical\\nand Earth Resources\\nEngineering with Colorado\\nState University (USA)\\nDual Degree Master’s\\nProgram in Water\\nEngineering and\\nManagement with Colorado\\nState University (USA)\\nDual Degree Master’s\\nProgram in Water\\nEngineering and\\nManagement with the\\nUniversity of Iowa (USA)\\n (/)', metadata={'source': 'C:\\\\Users\\\\Haneesha\\\\OneDrive\\\\文件\\\\Boooooookkkkkkssss\\\\Academic Programs - Asian Institute of Technology.pdf', 'file_path': 'C:\\\\Users\\\\Haneesha\\\\OneDrive\\\\文件\\\\Boooooookkkkkkssss\\\\Academic Programs - Asian Institute of Technology.pdf', 'page': 3, 'total_pages': 9, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36', 'producer': 'Skia/PDF m122', 'creationDate': \"D:20240321123743+00'00'\", 'modDate': \"D:20240321123743+00'00'\", 'trapped': ''})]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.get_relevant_documents(\"Who are the faculty in Data Science and AI?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Memory\n",
    "\n",
    "One of the core utility classes underpinning most (if not all) memory modules is the ChatMessageHistory class. This is a super lightweight wrapper that provides convenience methods for saving HumanMessages, AIMessages, and then fetching them all.\n",
    "\n",
    "You may want to use this class directly if you are managing memory outside of a chain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatMessageHistory(messages=[])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "history = ChatMessageHistory()\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.add_user_message('hi')\n",
    "history.add_ai_message('Whats up?')\n",
    "history.add_user_message('How are you')\n",
    "history.add_ai_message('I\\'m quite good. How about you?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatMessageHistory(messages=[HumanMessage(content='hi'), AIMessage(content='Whats up?'), HumanMessage(content='How are you'), AIMessage(content=\"I'm quite good. How about you?\")])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Memory types\n",
    "\n",
    "There are many different types of memory. Each has their own parameters, their own return types, and is useful in different scenarios. \n",
    "- Converstaion Buffer\n",
    "- Converstaion Buffer Window"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What variables get returned from memory\n",
    "\n",
    "Before going into the chain, various variables are read from memory. These have specific names which need to align with the variables the chain expects. You can see what these variables are by calling memory.load_memory_variables({}). Note that the empty dictionary that we pass in is just a placeholder for real variables. If the memory type you are using is dependent upon the input variables, you may need to pass some in."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, you can see that load_memory_variables returns a single key, history. This means that your chain (and likely your prompt) should expect an input named history. You can usually control this variable through parameters on the memory class. For example, if you want the memory variables to be returned in the key chat_history you can do:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converstaion Buffer\n",
    "This memory allows for storing messages and then extracts the messages in a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: hi\\nAI: What's up?\\nHuman: How are you?\\nAI: I'm quite good. How about you?\"}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "memory.save_context({'input':'hi'}, {'output':'What\\'s up?'})\n",
    "memory.save_context({\"input\":'How are you?'},{'output': 'I\\'m quite good. How about you?'})\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='hi'),\n",
       "  AIMessage(content=\"What's up?\"),\n",
       "  HumanMessage(content='How are you?'),\n",
       "  AIMessage(content=\"I'm quite good. How about you?\")]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages = True)\n",
    "memory.save_context({'input':'hi'}, {'output':'What\\'s up?'})\n",
    "memory.save_context({\"input\":'How are you?'},{'output': 'I\\'m quite good. How about you?'})\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conversation Buffer Window\n",
    "- it keeps a list of the interactions of the conversation over time. \n",
    "- it only uses the last K interactions. \n",
    "- it can be useful for keeping a sliding window of the most recent interactions, so the buffer does not get too large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: How are you?\\nAI: I'm quite good. How about you?\"}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "memory.save_context({'input':'hi'}, {'output':'What\\'s up?'})\n",
    "memory.save_context({\"input\":'How are you?'},{'output': 'I\\'m quite good. How about you?'})\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Chain\n",
    "\n",
    "Using an LLM in isolation is fine for simple applications, but more complex applications require chaining LLMs - either with each other or with other components.\n",
    "\n",
    "An `LLMChain` is a simple chain that adds some functionality around language models.\n",
    "- it consists of a `PromptTemplate` and a `LM` (either an LLM or chat model).\n",
    "- it formats the prompt template using the input key values provided (and also memory key values, if available), \n",
    "- it passes the formatted string to LLM and returns the LLM output.\n",
    "\n",
    "Note : [Download Fastchat Model Here](https://huggingface.co/lmsys/fastchat-t5-3b-v1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 2] The system cannot find the file specified: './models'\n",
      "c:\\Users\\Haneesha\\OneDrive\\Desktop\\NLP\\A7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'git' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "#%cd ./models\n",
    "#!git clone 'https://huggingface.co/lmsys/fastchat-t5-3b-v1.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the absolute path to the model directory\n",
    "model_id = '/path/to/models/fastchat-t5-3b-v1.0/'\n",
    "\n",
    "# Or provide the repo_id of the model on the Hugging Face Hub\n",
    "model_id = 'username/model_name'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50d33a87d7134de4a3c121b5683885a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "No GPU found. A GPU is needed for quantization.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 20\u001b[0m\n\u001b[0;32m     11\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mpad_token_id \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39meos_token_id\n\u001b[0;32m     13\u001b[0m bitsandbyte_config \u001b[38;5;241m=\u001b[39m BitsAndBytesConfig(\n\u001b[0;32m     14\u001b[0m     load_in_4bit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     15\u001b[0m     bnb_4bit_quant_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnf4\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     16\u001b[0m     bnb_4bit_compute_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat16,\n\u001b[0;32m     17\u001b[0m     bnb_4bit_use_double_quant \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     18\u001b[0m )\n\u001b[1;32m---> 20\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForSeq2SeqLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbitsandbyte_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#caution Nvidia\u001b[39;49;00m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_in_8bit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     25\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m pipe \u001b[38;5;241m=\u001b[39m pipeline(\n\u001b[0;32m     28\u001b[0m     task\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext2text-generation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     29\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     35\u001b[0m     }\n\u001b[0;32m     36\u001b[0m )\n\u001b[0;32m     38\u001b[0m llm \u001b[38;5;241m=\u001b[39m HuggingFacePipeline(pipeline \u001b[38;5;241m=\u001b[39m pipe)\n",
      "File \u001b[1;32mc:\\Users\\Haneesha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:566\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    565\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 566\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    572\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Haneesha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_utils.py:2897\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   2895\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load_in_8bit \u001b[38;5;129;01mor\u001b[39;00m load_in_4bit:\n\u001b[0;32m   2896\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m-> 2897\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo GPU found. A GPU is needed for quantization.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2898\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_accelerate_available() \u001b[38;5;129;01mand\u001b[39;00m is_bitsandbytes_available()):\n\u001b[0;32m   2899\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m   2900\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `load_in_8bit=True` requires Accelerate: `pip install accelerate` and the latest version of\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2901\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m bitsandbytes `pip install -i https://test.pypi.org/simple/ bitsandbytes` or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2902\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `pip install bitsandbytes`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2903\u001b[0m         )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: No GPU found. A GPU is needed for quantization."
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, pipeline, AutoModelForSeq2SeqLM\n",
    "from transformers import BitsAndBytesConfig\n",
    "from langchain import HuggingFacePipeline\n",
    "import torch\n",
    "\n",
    "model_id = 'lmsys/fastchat-t5-3b-v1.0'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_id)\n",
    "\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "bitsandbyte_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True,\n",
    "    bnb_4bit_quant_type = \"nf4\",\n",
    "    bnb_4bit_compute_dtype = torch.float16,\n",
    "    bnb_4bit_use_double_quant = True\n",
    ")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config = bitsandbyte_config, #caution Nvidia\n",
    "    device_map = 'auto',\n",
    "    load_in_8bit = True\n",
    ")\n",
    "\n",
    "pipe = pipeline(\n",
    "    task=\"text2text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens = 256,\n",
    "    model_kwargs = {\n",
    "        \"temperature\" : 0,\n",
    "        \"repetition_penalty\": 1.5\n",
    "    }\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline = pipe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Class ConversationalRetrievalChain](https://api.python.langchain.com/en/latest/_modules/langchain/chains/conversational_retrieval/base.html#ConversationalRetrievalChain)\n",
    "\n",
    "- `retriever` : Retriever to use to fetch documents.\n",
    "\n",
    "- `combine_docs_chain` : The chain used to combine any retrieved documents.\n",
    "\n",
    "- `question_generator`: The chain used to generate a new question for the sake of retrieval. This chain will take in the current question (with variable question) and any chat history (with variable chat_history) and will produce a new standalone question to be used later on.\n",
    "\n",
    "- `return_source_documents` : Return the retrieved source documents as part of the final result.\n",
    "\n",
    "- `get_chat_history` : An optional function to get a string of the chat history. If None is provided, will use a default.\n",
    "\n",
    "- `return_generated_question` : Return the generated question as part of the final result.\n",
    "\n",
    "- `response_if_no_docs_found` : If specified, the chain will return a fixed response if no docs are found for the question.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`question_generator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONDENSE_QUESTION_PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_generator = LLMChain(\n",
    "    llm = llm,\n",
    "    prompt = CONDENSE_QUESTION_PROMPT,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Comparing both of them'\n",
    "chat_history = \"Human:What is Machine Learning\\nAI:\\nHuman:What is Deep Learning\\nAI:\"\n",
    "\n",
    "question_generator({'chat_history' : chat_history, \"question\" : query})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`combine_docs_chain`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_chain = load_qa_chain(\n",
    "    llm = llm,\n",
    "    chain_type = 'stuff',\n",
    "    prompt = PROMPT,\n",
    "    verbose = True\n",
    ")\n",
    "doc_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = \"What is Transformers?\"\n",
    "input_document = retriever.get_relevant_documents(query)\n",
    "\n",
    "doc_chain({'input_documents':input_document, 'question':query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(\n",
    "    k=3, \n",
    "    memory_key = \"chat_history\",\n",
    "    return_messages = True,\n",
    "    output_key = 'answer'\n",
    ")\n",
    "\n",
    "chain = ConversationalRetrievalChain(\n",
    "    retriever=retriever,\n",
    "    question_generator=question_generator,\n",
    "    combine_docs_chain=doc_chain,\n",
    "    return_source_documents=True,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    "    get_chat_history=lambda h : h\n",
    ")\n",
    "chain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_question = \"Who are you by the way?\"\n",
    "answer = chain({\"question\":prompt_question})\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_question = \"What is the Transformers?\"\n",
    "answer = chain({\"question\":prompt_question})\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_question = \"Is it a statistical model?\"\n",
    "answer = chain({\"question\":prompt_question})\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
